{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2305437-81c4-445c-b8e5-ecdd934dc829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef2221b7-6c2e-476c-a198-c50825664180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mots d'anglais à apprendre:\n",
      "1. Hamas\n",
      "2. earlier\n",
      "3. released\n",
      "4. 14\n",
      "5. Israeli\n",
      "6. hostages\n",
      "7. -\n",
      "8. including\n",
      "9. nine\n",
      "10. children\n",
      "11. -\n",
      "12. and\n",
      "13. three\n",
      "14. foreign\n",
      "15. nationals.\n",
      "16. Raye\n",
      "17. on\n",
      "18. rising\n",
      "19. to\n",
      "20. fame,\n",
      "21. people\n",
      "22. abusing\n",
      "23. their\n",
      "24. power\n",
      "25. and\n",
      "26. what\n",
      "27. the\n",
      "28. future\n",
      "29. holds.\n",
      "30. Organisers\n",
      "31. say\n",
      "32. the\n",
      "33. event\n",
      "34. is\n",
      "35. the\n",
      "36. first\n",
      "37. of\n",
      "38. its\n",
      "39. kind\n",
      "40. since\n",
      "41. the\n",
      "42. Israel-Gaza\n",
      "43. war\n",
      "44. broke\n",
      "45. out.\n",
      "46. The\n",
      "47. ex-police\n",
      "48. officer\n",
      "49. who\n",
      "50. murdered\n",
      "51. George\n",
      "52. Floyd\n",
      "53. in\n",
      "54. Minneapolis\n",
      "55. is\n",
      "56. reported\n",
      "57. to\n",
      "58. be\n",
      "59. in\n",
      "60. a\n",
      "61. stable\n",
      "62. condition.\n",
      "63. Terry\n",
      "64. Venables\n",
      "65. was\n",
      "66. \"the\n",
      "67. best\n",
      "68. English\n",
      "69. coach\n",
      "70. we've\n",
      "71. had\",\n",
      "72. says\n",
      "73. Gary\n",
      "74. Lineker\n",
      "75. as\n",
      "76. he\n",
      "77. leads\n",
      "78. tributes\n",
      "79. to\n",
      "80. the\n",
      "81. former\n",
      "82. England\n",
      "83. boss.\n",
      "84. Watch\n",
      "85. live\n",
      "86. coverage\n",
      "87. and\n",
      "88. follow\n",
      "89. text\n",
      "90. commentary\n",
      "91. as\n",
      "92. Australia\n",
      "93. take\n",
      "94. on\n",
      "95. Italy\n",
      "96. in\n",
      "97. the\n",
      "98. Davis\n",
      "99. Cup\n",
      "100. final\n"
     ]
    }
   ],
   "source": [
    "def extraire_mots_anglais(url, nombre_mots):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    mots = []\n",
    "\n",
    "    # Logique spécifique pour extraire les mots du site web\n",
    "    # L'exemple suivant suppose que les mots sont dans des balises <p>\n",
    "    paragraphs = soup.find_all('p')\n",
    "    for paragraph in paragraphs:\n",
    "        mots.extend(paragraph.text.split())\n",
    "\n",
    "        if len(mots) >= nombre_mots:\n",
    "            break\n",
    "\n",
    "    return mots[:nombre_mots]\n",
    "\n",
    "# Exemple d'utilisation avec un site web factice\n",
    "url_du_site = 'https://www.bbc.com/'\n",
    "nombre_mots_a_extraire = 100\n",
    "\n",
    "mots_anglais = extraire_mots_anglais(url_du_site, nombre_mots_a_extraire)\n",
    "\n",
    "print(\"Mots d'anglais à apprendre:\")\n",
    "for index, mot in enumerate(mots_anglais, 1):\n",
    "    print(f\"{index}. {mot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3236084-fda1-4586-a5b1-5916f5c286aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mots d'anglais à apprendre (sélection aléatoire):\n",
      "1. why\n",
      "2. coal-fired\n",
      "3. full\n",
      "4. a\n",
      "5. differently\n",
      "6. energy\n",
      "7. nonprofit\n",
      "8. stuff.\n",
      "9. could\n",
      "10. has\n",
      "11. it\n",
      "12. grid-forming\n",
      "13. people\n",
      "14. now.\n",
      "15. counterparts,\n",
      "16. Vol.\n",
      "17. in\n",
      "18. Now\n",
      "19. their\n",
      "20. antimatter\n",
      "21. future\n",
      "22. relies\n",
      "23. and\n",
      "24. ©\n",
      "25. for\n",
      "26. 1991,\n",
      "27. founded\n",
      "28. and\n",
      "29. the\n",
      "30. news\n",
      "31. As\n",
      "32. help\n",
      "33. 501(c)(3)\n",
      "34. an\n",
      "35. full\n",
      "36. independent,\n",
      "37. Today,\n",
      "38. empower\n",
      "39. news\n",
      "40. education\n",
      "41. No.\n",
      "42. a\n",
      "43. are\n",
      "44. technology.\n",
      "45. 18,\n",
      "46. 204\n",
      "47. Science\n",
      "48. November\n",
      "49. News\n",
      "50. was\n",
      "51. rights\n",
      "52. companion.\n",
      "53. evaluate\n",
      "54. membership\n",
      "55. subscription\n",
      "56. for\n",
      "57. much\n",
      "58. one\n",
      "59. source\n",
      "60. a\n",
      "61. print\n",
      "62. Science,\n",
      "63. in\n",
      "64. inverters\n",
      "65. accurate\n",
      "66. the\n",
      "67. with\n",
      "68. In\n",
      "69. physicists\n",
      "70. to\n",
      "71. News\n",
      "72. If\n",
      "73. archives\n",
      "74. on\n",
      "75. them.\n",
      "76. 104\n",
      "77. 2023\n",
      "78. behave\n",
      "79. mission\n",
      "80. 1921\n",
      "81. key\n",
      "82. a\n",
      "83. plants\n",
      "84. may\n",
      "85. it\n",
      "86. Not\n",
      "87. of\n",
      "88. editions.\n",
      "89. Subscribers,\n",
      "90. medicine\n",
      "91. the\n",
      "92. energetic\n",
      "93. Society\n",
      "94. All\n",
      "95. full\n",
      "96. 53-0196483).\n",
      "97. and\n",
      "98. and\n",
      "99. Become\n",
      "100. the\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "\n",
    "def extraire_mots_anglais(url, nombre_mots):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    mots = []\n",
    "\n",
    "    # Logique spécifique pour extraire les mots du site web\n",
    "    # L'exemple suivant suppose que les mots sont dans des balises <p>\n",
    "    paragraphs = soup.find_all('p')\n",
    "    \n",
    "    # Concaténer tous les mots dans une seule liste\n",
    "    for paragraph in paragraphs:\n",
    "        mots.extend(paragraph.text.split())\n",
    "\n",
    "    # Sélectionner un échantillon aléatoire de mots\n",
    "    mots_aleatoires = random.sample(mots, min(nombre_mots, len(mots)))\n",
    "\n",
    "    return mots_aleatoires\n",
    "\n",
    "# Exemple d'utilisation avec un site web factice\n",
    "url_du_site = 'https://www.sciencenews.org/'\n",
    "nombre_mots_a_extraire = 100\n",
    "\n",
    "mots_anglais = extraire_mots_anglais(url_du_site, nombre_mots_a_extraire)\n",
    "\n",
    "print(\"Mots d'anglais à apprendre (sélection aléatoire):\")\n",
    "for index, mot in enumerate(mots_anglais, 1):\n",
    "    print(f\"{index}. {mot}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0dcb67-0e33-46dd-848a-dbd702e1b48d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
